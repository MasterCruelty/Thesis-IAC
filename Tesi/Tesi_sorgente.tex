%
% Tesi D.S.I. - modello preso da
% Stanford University PhD thesis style -- modifications to the report style
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%--fix template
\makeatletter
\let\my@xfloat\@xfloat
\makeatother
%--end fix
\documentclass[a4paper,12pt]{report}
%    \renewcommand{\baselinestretch}{1.6}      % interline spacing
%
% \includeonly{}
%
%			PREAMBOLO
%
\usepackage[a4paper]{geometry}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{graphicx}
\graphicspath{{./img/}}
\usepackage{url}
\usepackage{hyperref}
\usepackage{epsfig}
\usepackage[italian]{babel}
\usepackage{setspace}
\usepackage{tesi}
%--definizione linguaggio
\usepackage{listings}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Bash,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
%--fine definizione linguaggio

%--fix template
\makeatletter
\def\@xfloat#1[#2]{
	\my@xfloat#1[#2]%
	\def\baselinestretch{1}%
	\@normalsize \normalsize
}
\makeatother
%--end fix



% per le accentate
\usepackage[utf8]{inputenc}
%
\newtheorem{myteor}{Teorema}[section]
%
\newenvironment{teor}{\begin{myteor}\sl}{\end{myteor}}
%
%
%			TITOLO
%
\begin{document}
\begin{center}
\includegraphics[width=\textwidth]{Logo.jpg}
\title{Realizzazione di una soluzione IAC (Infrastructure As Code) che consenta il rilascio di un'infrastruttura per ambiti DevOps}
\end{center}
\author{\textbf{Roberto Antoniello}}
\dept{Corso di Laurea in Informatica} 
\anno{2022-2023}
\matricola{\textbf{875693}}
\relatore{Prof. Valentina Ciriani}
\correlatore{Mario Petrella}

\beforepreface

\afterpreface
% 
% 
% 
\chapter{Introduzione}
\section{IAC: definizione e vantaggi}
La metodologia IAC(Infrastructure As Code), in italiano "infrastruttura come codice", è una strategia che punta a gestire l'intero ciclo di vita di un'infrastruttura mediante codice. Quindi non c'è bisogno di configurazione hardware fisica o strumenti interattivi esterni, è sufficiente uno o più linguaggi dichiarativi o di scripting e compilare correttamente dei file di definizione.\cite{iacdef} \\ 
In questo modo è molto più semplice e rapido modificare o eseguire miglioramenti al sistema senza dover ripensare completamente la struttura o stravolgerne le componenti. \\
Come vedremo nei successivi paragrafi, la potenza di alcune delle tecnologie trattate lungo lo sviluppo di questo progetto risiede proprio nel fatto di poter essere gestite direttamente tramite codice.\\
In questo capitolo introduttivo saranno descritti gli obiettivi prefissati per questo progetto, le fasi principali che sono state svolte e una breve descrizione delle tecnologie utilizzate. \\
In questo modo sarà più immediato richiamare alcuni concetti che useremo nei capitoli successivi.
\section{Obiettivi del progetto}
Gli obiettivi principali prefissati per questo progetto di tirocinio sono stati i seguenti:
\begin{enumerate}
\item \textit{Acquisire competenze in ambito DevOps.}
\item \textit{Acquisire conoscenze sul ciclo di vita di un'infrastruttura.}
\item \textit{Costruire un'infrastruttura in grado di essere rilasciata attraverso il cloud e sulla quale fosse possibile rilasciare applicazioni basate su microservizi.}
\end{enumerate}
\subsection{Dal metodo tradizionale all'approccio DevOps}
DevOps è una metodologia che punta a ridurre in modo considerevole i tempi di rilascio di nuovo software incorporando nello stesso di team di sviluppo le competenze necessarie per costruire l'infrastruttura adatta al rilascio del software grazie ai concetti di container, microservizi e cloud computing.\\
Tradizionalmente il processo di rilascio avveniva più lentamente nell'arco di mesi. Il team di sviluppo doveva coordinarsi con gli altri team per le diverse fasi dello sviluppo. Oggi invece con lo sviluppo DevOps si possono eseguire tutte le fasi senza dover aspettare un team separato, garantendo che il tempo di rilascio delle modifiche del software possa avvenire con frequenza oraria o anche meno, oltre ad essere continuativo e automatico.\\
Un'ulteriore progresso in questo tipo di approcci è il DevSecOps, una strategia che va a integrare anche la sicurezza e il testing nel CI(Continuous Integration) e CD(Continuous Deployment). \\La difficoltà che sorge nel DevSecOps è la risoluzione dei problemi legati alla sicurezza internamente al team di sviluppo, poichè gli sviluppatori devono prima acquisire le competenze necessarie per risolvere questo tipo di problemi.
\subsection{Ciclo di vita dell'infrastruttura}
Si intende in tal senso che l'obiettivo specifico fosse di comprendere l'intero ciclo a partire dall'analisi dei requisiti fino ad arrivare alla progettazione e implementazione finale del sistema.
\section{Fasi principali svolte}
Le principali fasi svolte durante il progetto di tirocinio sono state le seguenti:
\begin{enumerate}
\item \textit{Studio delle tecnologie coinvolte.} \\
Durante questa fase sono state approcciate diverse tecnologie per la prima volta. Vi è stato un primo apprendimento teorico dei concetti che ruotavano attorno al funzionamento di questi strumenti, mentre successivamente tali concetti sono stati applicati in maniera pratica eseguendo diversi test.
\item \textit{Progettazione dell'infrastruttura.} \\
In questa fase è stata eseguita un'analisi dei requisiti e definita la struttura dell'infrastruttura finale. Per fare ciò è stata sfruttata la fase iniziale di studio per capire in che modo le varie tecnologie andassero collegate tra loro in maniera corretta.
\item \textit{Implementazione del sistema.}\\
In questa fase finale è stata implementata l'infrastruttura in funzione dei disegni progettuali prodotti in precedenza.\\
Una volta costruito il sistema e quindi l'ambiente operativo di base, è stata poi rilasciata al suo interno un'applicazione a microservizi. \\
Come da requisiti iniziali anche le successive modifiche all'applicazione potevano avvenire in automatico in regola con la CI/CD. \\
\end{enumerate}

\section{Tecnologie utilizzate}
\begin{figure}[h]
	\includegraphics[width=0.6\textwidth]{tech_used}
    \caption{The DevOps infinity loop(ogni tecnologia utilizzata nel proprio settore) \cite{devopsloopimg}}
    \label{fig:tech_used}
\end{figure}

In questa figura è possibile osservare l'elenco delle tecnologie utilizzate, ognuna posta nel proprio settore di appartenenza lungo il ciclo infinito dello sviluppo DevOps.\cite{devopsloop}\\
Questo ciclo parte dalla stesura del codice fino ad arrivare al suo monitoraggio per poi ricominciare da capo senza mai concludersi.\\
Per quanto riguarda il versionamento del codice è stato utilizzato \textbf{Git}. \\
Spostandoci sul lato del deploy notiamo \textbf{Azure} che è il cloud provider scelto durante la fase di studio, \textbf{Terraform} per la vera e propria infrastruttura a livello di codice e \textbf{Docker} per la sua funzionalità nella creazione di container.\\
Potremo invece considerare \textbf{Kubernetes}  come il "controller" di tutto il sistema costruito durante il progetto.\\
Infine per la parte di build e release è stato utilizzato \textbf{Jenkins} per tutto ciò che riguarda il continuo rilascio in maniera automatica.\\
\textit{Nel prossimo capitolo andremo ad approfondire meglio i concetti principali di queste tecnologie e come sono state utilizzate nel contesto del progetto.}

%-------------------------------------------------

\chapter{Fase di studio e analisi dei requisiti}
\section{Tecnologie}
Come anticipato, in questa sezione si parlerà più nel dettaglio delle tecnologie già menzionate e più nel dettaglio della fase di studio.
\subsection{Docker}
Docker è un software progettato per permettere di eseguire applicazioni in ambienti isolati minimali e facilmente distribuibili, anche detti container. \cite{docker} \\
In particolare questi container non sono altro che delle applicazioni "virtualizzate" che condividono il kernel del sistema operativo della macchina che li ospita. Risultano quindi isolate e facilmente distribuibili. \\
Nel contesto del progetto Docker è stato usato direttamente solo per il versionamento delle immagini dei microservizi. È stato invece usato in modo implicito e indiretto all'interno di Kubernetes. \\ 

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{docker}
    \caption{Esempio di rappresentazione di alcuni container rispetto al kernel del sistema operativo della macchina ospitante. \cite{dockerimg}}
    \label{fig:docker}
\end{figure}


\subsection{Kubernetes}
Kubernetes, anche chiamata k8s, è una piattaforma open source che automatizza le operazioni sui container. Grazie ad essa vengono eliminati molti dei processi manuali coinvolti nel deploy di applicazioni in container. \\
Questa caratteristica viene chiamata orchestrazione, dunque non è più necessario manipolare i container a mano con diversi comandi Docker, ma è sufficiente scrivere un manifesto in codice formato YAML. In questo file vengono definite le specifiche del container e ogni volta che dovrà essere modificato basterà modificare il codice e successivamente applicare di nuovo il file. Il container stesso viene posto all'interno di un oggetto a un livello più alto di atrazione chiamato pod.\\
È possibile mettere in cluster gruppi di nodi su cui sono in esecuzioni dei container e Kubernetes aiuta a gestirli in modo facile ed efficiente.\\
Questa tecnologia si pone a un livello d'astrazione più alto rispetto a Docker e i nodi all'interno del cluster contengono già al loro interno un container runtime.\cite{kubernetes}\\ 
Un'ulteriore vantaggio legato a Kubernetes risiede nei suoi meccanismi di autoscale sia orizzontale che verticale oltre che a tecniche di scheduling interne, così da garantire che i servizi delle applicazioni siano sempre disponibili.


\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{k8s}
    \caption{Una rappresentazione grafica di un cluster Kubernetes. \cite{k8simg}}
    \label{fig:k8s}
\end{figure}

Ad esempio nella figura 3 si può notare che il cluster è configurato con 4 nodi, uno master e tre worker. All'interno del master vi sono tutte le componenti di sistema di Kubernetes, mentre sui nodi worker risiedono i microservizi deployati. Il contenuto dei manifesti YAML viene comunicato al nodo master che successivamente va a schedulare i container in modo appropriato sui vari nodi.

\subsection{Azure}
Nel corso della fase di studio, tra le varie alternative possibili è stato scelto Azure come cloud provider su cui fare affidamento.\\
I vantaggi di usare il cloud risiedono nel fatto che non è più necessario costruirsi un proprio datacenter privato acquistando hardware e gestendolo privatamente, ma noleggiandolo da società terze sfruttando la rete.\cite{cloud}\\
L'utilizzo delle macchine è pagato sulla base dell'effettivo consumo e come detto poc'anzi questo fa si che i costi da sostenere siano notevolmente più bassi rispetto all'acquisto, installazione e manutenzione in loco.\\
Nel contesto del progetto Azure è stato usato principalmente per il suo servizio legato ai cluster Kubernetes, chiamato Azure Kubernetes Service o in forma abbreviata AKS. Oltre alla convenienza sul lato economico, un vantaggio in questo caso specifico sta nel ritrovarsi con un cluster già pronto e operativo con un singolo comando dalla CLI di Azure o con pochi click dal portale web.\\
Alternativamente, se dovessimo fare a meno di questo servizio, saremmo costretti a configurare a mano le diverse macchine per collegarle insieme e formare il cluster. 
\begin{lstlisting}[caption={\\\textit{Esempio di comando per creare un cluster Kubernetes come servizio di Azure da Azure CLI. Gli argomenti passati sono il gruppo risorse in cui deployare la risorsa di tipo AKS, il nome attribuito al cluster e il numero di nodi desiderati.}}]
az aks create \
  --resource-group <gruppo-risorse> \
  --name <nome-cluster> \
  --node-count <n> \
\end{lstlisting}

\subsection{Terraform}
Si tratta di una tecnologia di automazione dotata di un proprio linguaggio dichiarativo HCL(Hashicorp Configuration Language), con la quale è possibile creare, modificare e eventualmente distruggere risorse descritte nel codice.\\
Nel contesto del progetto Terraform è stato utilizzato per definire le specifiche del cluster Kubernetes come servizio di Azure. Una volta che è stato definito tramite codice, non è stato più necessario andarlo a creare attraverso Azure stesso, ma semplicemente facendo compilare e applicare il codice.

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{terraform}
    \caption{Raffigurazione di come Terraform possa essere usato con diversi tipi di servizi e differenti provider. \cite{terraformimg}}
    \label{fig:terraform}
\end{figure}

\subsection{Jenkins}
Questo è stato uno strumento fondamentale ai fini del progetto, nonché ponte di collegamento tra tutte le tecnologie introdotte finora. \\
È un software open source di supporto allo sviluppo che permette facilmente l'integrazione continua e automatica nei rilasci del software.\cite{jenkins}\\
Jenkins è stato utilizzato in questo progetto per costruire delle cosiddette pipeline, ovvero delle collezioni di eventi che succedono uno dopo l'altro. Andando più nel dettaglio, ogni pipeline prodotta è divisa in diversi blocchi, ognuno dei quali esegue determinate azioni tramite un apposito script in Bash.\\
Ogni qualvolta viene fatta una modifica, una pipeline specifica viene attivata ed eseguita dall'inizio fino alla fine, il tutto in autonomia e senza bisogno di passi manuali.

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{jenkins}
    \caption{Rappresentazione grafica di una pipeline eseguita da Jenkins. \cite{jenkinsimg}}
    \label{fig:jenkins}
\end{figure}

\section{Requisiti}
Richiamando in breve i requisiti e analizzandoli, l'infrastruttura finale doveva rispettare le seguenti richieste:\\
\begin{enumerate}
\item \textit{Deve essere realizzata tramite una soluzione IAC.}
\item \textit{Deve essere rilasciata attraverso il cloud.}
\item \textit{Deve essere in grado di ospitare sopra di essa applicazioni a microservizi.}
\item \textit{Deve garantire che le modifiche a questi microservizi vengano integrate e deployate in automatico. }
\end{enumerate}
\subsection{collegamenti tra le tecnologie}
Si tratta di una delle parti più complesse svolte durante il tirocinio. Essenzialmente è stato un punto di transizione tra la fase di studio e la fase di progettazione.\\
Ora che abbiamo introdotto a sufficienza tutti gli strumenti utilizzati, è necessario collegarli tra loro e farli comunicare correttamente, così da completare metaforicamente un grande puzzle.\\
Ad esempio Terraform, Kubernetes e Azure sono stati collegati tra loro come se fossero un'entità unica. Kubernetes ci fornisce il controllo sui container, Azure un servizio per avere il cluster già pronto e infine Terraform ci permette di creare la risorsa scrivendo solo codice. \\
La difficoltà principale nel fare ciò è stato capire a fondo che ruolo svolgeva ogni pezzo così da sapere in che modo serviva per far funzionare al meglio il pezzo successivo.

\chapter{Progettazione dell'infrastruttura}
\section{Casi d'uso}

\begin{figure}[h]
	\includegraphics[width=0.7\textwidth]{casi_uso}
    \caption{Diagramma dei casi d'uso considerati in formato UML}
    \label{fig:casi_uso}
\end{figure}
In questo diagramma sono rappresentati graficamente i casi d'uso considerati durante la progettazione ai fini dell'implementazione finale.\\
Il sistema è utilizzabile quindi da due tipologie di utenti, chi si occupa della parte DevOps vera e propria e chi invece è lo sviluppatore classico.\\
L'utente DevOps è in grado di eseguire push di eventuali modifiche di codice ai microservizi, ma ha anche i privilegi di amministrazione per modificare il codice lato Terraform o aggiornare delle componenti nelle pipeline. Lo sviluppatore invece può utilizzare l'infrastruttura solo indirettamente eseguendo push di codice. Ognuna di queste azioni attiva uno specifico job jenkins che farà eseguire una pipeline.\\
\section{Definizione dell'infrastruttura}

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{disegno_struttura_infra}
    \caption{Disegno che definisce il funzionamento dell'intero sistema sviluppato.}
    \label{fig:disegno_struttura_infra}
\end{figure}

È possibile notare che l'infrastruttura è divisa in tre macro aree.\\
A partire da sinistra abbiamo tutto ciò che riguarda il versionamento del codice. Alla base vi è un repository Git, che può essere quello che contiene il codice Terraform oppure uno dei repository che contiene il codice di uno dei microservizi che andranno ad essere deployati sopra il sistema.\\
Per dare più chiarezza sull'utilizzo dei repository dei microservizi, essenzialmente tramite essi è stato preso il codice alla fonte ed è stato definito al loro interno un manifesto in formato YAML per le specifiche del container.\\
Nel momento in cui viene eseguito un push sul repository, in particolare sul ramo master, viene attivato un trigger da Jenkins, il quale farà partire l'esecuzione della pipeline collegata.\\
Come prima cosa quindi viene eseguito un pull delle modifiche o direttamente clonato l'intero repository. Successivamente il codice viene compilato, ne viene costruita e versionata l'immagine per il container, poi viene eseguito un push su un repository Docker privato e infine viene eseguito il deploy effettivo sul cluster Kubernetes.\\
Il repository privato per le immagini è stato ospitato tramite Nexus che è una tecnologia dedicata a questo tipo di utilizzo.
\subsection{Ulteriori dettagli progettuali}
Ora che è stato presentato il disegno che rappresenta la definizione completa, andremo a considerare separatamente i casi d'uso.

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{modifica_terraform}
    \caption{Dettaglio progettuale per la sola modifica delle specifiche del sistema.}
    \label{fig:modifica_terraform}
\end{figure} 

Richiamando il concetto nel precedente paragrafo, nel momento in cui il codice Terraform viene modificato e si verifica un push sul repository, Jenkins attiva il trigger e la pipeline specifica. In questa casistica viene solo eseguito lo script in Bash che va a compilare e eseguire il codice HCL, causando l'aggiunta, la modifica oppure la distruzione di risorse.\\

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{push_modifica}
    \caption{Dettaglio progettuale per il deploy di nuove modifiche dei microservizi.}
    \label{fig:push_modifica}
\end{figure}

Sulla figura 9 non vi è molto altro da aggiungere, fondamentalmente tratta lo stesso processo spiegato per la figura 7, tolta tutta la parte legata a Terraform e concentrandosi solo sul deploy di nuove modifiche.

\chapter{Implementazione dell'infrastruttura}
\section{Codice Terraform e pipeline dedicata}
La fase di implementazione di tutto il sistema progettato e descritto nel capitolo precedente, è iniziata costruendo prima l'ambiente operativo di sviluppo. \\
Per fare ciò è stato prima prodotto il codice Terraform e successivamente sviluppata la pipeline dedicata al rilascio delle modifiche di tale codice.\\

\subsection{Definizione via codice}

All'interno dei sorgenti HCL sono state definite le specifiche che doveva avere il cluster Kubernetes di Azure. Nel dettaglio è stato deciso di quanti nodi si doveva comporre, la dimensione delle macchine e il numero massimo di pod che poteva sostenere ogni nodo.\\
È stato impostato l'autoscale sui nodi con un minimo di tre fino a un massimo di sei. Il numero massimo di pod è stato impostato a 30.\\
Le informazioni relative al gruppo risorse e la regione geografica sono impostate come variabili all'interno di un altro sorgente e possono essere richiamate tramite il prefisso 'var'.
\begin{lstlisting}[caption={\\\textit{Codice sorgente all'interno del file main.tf.\\ }}]
#Definizione della risorsa di tipo cluster Kubernetes
resource "azurerm_kubernetes_cluster" "k8s" {
  name                = "k8s-cluster-iac-${random_string.suffix.result}"
  location            = var.resource_group_location
  resource_group_name = var.resource_group_name
  dns_prefix          = "aks-dns"

  default_node_pool {
    name                = "agent"
    node_count          = 3
    vm_size             = "Standard_DS2_v2"
    max_pods            = 30
    enable_auto_scaling = true
    min_count           = 3
    max_count           = 6
  }

  identity {
    type = "SystemAssigned"
  }
  depends_on = [
    random_string.suffix
  ]
}

#risorsa di tipo stringa per generare il suffisso di 3 caratteri casuali sul nome della risorsa
resource "random_string" "suffix" {
  length  = 3
  special = false
}
\end{lstlisting}


\subsection{pipeline per la gestione delle modifiche}
La pipeline è stata divisa in 3 job diversi:
\begin{enumerate}
\item \textit{Git clone.} \\
Il primo passo fa semplicemente il clone del repository previo cancellazione della workspace directory per un clone pulito.\\
Jenkins fa partire questo primo job solo in caso di modifiche apportate lato Git e effettua un controllo ogni 15 minuti tramite un cronjob.
\item \textit{Build Terraform.} \\
In questo passo intermedio viene effettuato un login su Azure per assicurarsi di essere autenticati con la sottoscrizione corretta. In questo modo se la macchina dovesse essere utilizzata anche da altri utenti si evita di andare a fare modifiche su macchine che risiedono su altre sottoscrizioni Azure controllate da altri DevOps.\\
Fatto questo, viene effettuata la compilazione del codice e applicato allo stesso tempo, eseguendo eventualmente le azioni necessarie a modificare l'infrastruttura.\\
\item \textit{Deploy test.} \\
In questo ultimo passo viene semplicemente testato che il cluster Kubernetes sia stato creato correttamente e che sia funzionante, rilasciando sopra di esso una piccola applicazione di test.\\
Se il job precedente non viene concluso correttamente senza errori, la pipeline si ferma senza far cominciare quest'ultimo.\\
Questo accade per ogni concatenazione, avendo impostato tramite un apposito flag che i trigger di post-compilazione si attivano solo se la compilazione del processo attualmente in esecuzione è stabile.\\
\end{enumerate}

Le credenziali di accesso sono gestite tramite un sistema interno di Jenkins dove è possibile definirle comodamente per poi utilizzarle come variabili negli script Bash.\\
Per tenere traccia delle risorse attualmente attive, Terraform crea durante la prima esecuzione del codice un file di configurazione dello stato, il quale viene aggiornato di volta in volta. In questo modo se si esegue due volte lo stesso codice, non viene creata due volte la risorsa.

\begin{lstlisting}[caption={\\\textit{Frammento di codice relativo alla compilazione del codice Terraform.\\ Nelle ultime righe viene effettuato un collegamento con il cluster appena creato e lanciato un comando per visualizzare i nodi in modo da accertarsi che sia operativo.}}]
az login -u $azure_user -p $azure_psw
terraform init
terraform apply -auto-approve 

rs_group=$(terraform output resource_group_name | cut -d '"' -f 2)
cluster_name=$(terraform output kubernetes_cluster_name | cut -d '"' -f 2)
az aks get-credentials --resource-group $rs_group --name $cluster_name
kubectl get nodes
\end{lstlisting}

\section{Sviluppo pipeline per il rilascio dei micro servizi e modifica di puntamenti nel sorgente}
Una volta tirata su l'infrastruttura principale, è stato possibile in una seconda fase di implementazione andare a eseguire il rilascio finale dell'applicazione a microservizi citata in precedenza.
\subsection{Definizione delle pipeline}
L'applicazione era composta di quattro microservizi, il frontend e un api gateway.\\
Per ognuno di questi è stata sviluppata una pipeline composta dai seguenti job:\\
\begin{enumerate}
\item \textit{Git clone.}\\
Senza ripetersi, svolge un'azione identica al primo passo della pipeline per il codice Terraform.
\item \textit{Build codice.}\\
In questo step viene solamente compilato il codice in locale. Se non ci sono errori, si passa alla build dell'immagine Docker.
\item \textit{Build immagine.}\\
Prima di tutto viene eseguito il login sul repository Docker privato. Successivamente a partire dal codice già compilato viene eseguita la build dell'immagine usando il relativo Dockerfile presente nel repository clonato. Oltre a ciò viene anche eseguito il versionamento dell'immagine in modo da poter effetuare eventuali rollback in futuro.
\item \textit{Deploy k8s.}\\
In quest'ultimo passo viene anche qui eseguito un login su Azure, ci si collega al cluster corretto e infine viene applicato il manifesto YAML presente sul repository. \\ \\ \\
\end{enumerate}

\begin{lstlisting}[caption={\\\textit{Frammento di codice relativo al versionamento e alla build dell'immagine.}}]
#login sul repository docker
sudo docker login -u $docker_usr -p $docker_psw http://localhost:8083/repository/docker-hosted/
#Build dell'immagine dal Dockerfile(prelevo ultimo numero di versione dal repo docker)
img=interview_quiz
version=$(sudo docker images localhost:8083/repository/docker-hosted/interview_quiz --format "{{.Tag}}" | grep -A 1 latest | awk 'NR==2')
if [ -z "$version" ]; then
	version="v1"
else
    #estraggo il numero di versione e lo incremento di 1
    version_number=$(echo "$version" | cut -c 2-)
    new_version_number=$((version_number + 1))
    version="v$new_version_number"
fi
sudo docker build -t $img .
\end{lstlisting} 

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{pipeline}
    \caption{Una delle pipeline sviluppate vista dall'interfaccia web di Jenkins. Si possono vedere i quattro blocchi che la compongono per il rilascio delle modifiche del microservizio chiamato 'question'.}
    \label{fig:pipeline}
\end{figure}

\subsection{Modifica nel codice sorgente}
Dopo aver sviluppato le pipeline, per poter rendere l'applicazione già sviluppata compatibile con il sistema finora costruito, si è reso necessario apportare alcune piccole modifiche ai puntamenti presenti nel sorgente.\\
All'interno del servizio api gateway, sono state modificate tutte le rotte mettendo al loro posto il nome di dominio FQDN di ogni servizio definito nei manifesti per Kubernetes. Ad esempio se il microservizio si chiama \textit{question} ed è stato esposto sulla porta 8082, nella rotta viene inserito: \textit{http://question-service.interview-tool.svc.cluster.local:8082}\\ \\
Per come era strutturata l'applicazione architetturalmente, solo il frontend e l'api gateway sono stati esposti su internet, mentre i quattro microservizi sono raggiungibili solamente passando attraverso il gateway.\\ 
Un'ulteriore modifica è stata effettuata ai file di proprietà di ogni microservizio per regolare le rotte interne al cluster, sempre utilizzando il nome dominio FQDN dei servizi come fatto nel gateway. Sempre negli stessi file è stata modificata la rotta per il collegamento al database in modo da far collegare il microservizio al container del database definito tramite Kubernetes.\\ \\
Giunti a questo punto, il sistema risulta completo, dunque se lo sviluppatore di questa applicazione dovesse apportare delle modifiche a uno qualunque dei microservizi che la compongono, verrebbero deployate in tempo reale nell'arco di 15 minuti totalmente in automatico seguendo le procedure descritte nei precedenti paragrafi. \\ \\ \\ \\ \\ 


\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{app_micro}
    \caption{Schermata principale dell'applicazione una volta deployata con successo sull'infrastruttura sviluppata.}
    \label{fig:app_micro}
\end{figure}

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{app_micro2}
    \caption{Visualizzazione dei container in esecuzione per l'applicazione rilasciata nel suo namespace specifico. \\Ogni microservizio ha un suo database indipendente.}
    \label{fig:app_micro2}
\end{figure}

\begin{figure}[h]
	\includegraphics[width=1.0\textwidth]{app_micro3}
    \caption{Visualizzazione di tutti i servizi attivi per l'applicazione rilasciata.\\Come spiegato in precedenza, abbiamo solo due servizi esposti su internet, mentre gli altri 4 comunicano internamente al cluster e sono raggiungibili attraverso il gateway.}
    \label{fig:app_micro3}
\end{figure}

\chapter{Conclusioni}
\section{risultati raggiunti al termine}
Al termine di questo progetto i risultati raggiunti sono stati diversi, li ritroviamo qui di seguito:\\
\begin{itemize}
\item \textit{Appreso competenze in ambito DevOps.}\\
Nel corso del tirocinio è stato possibile approcciarsi da zero con questa metodologia di sviluppo, riuscendo a carpirne i vantaggi del suo utilizzo e a sviluppare nuove competenze.\\
\item \textit{Appreso conoscenze su diverse tecnologie.}\\
Grazie a questo progetto è stato possibile conoscere e acquisire competenze su molte tecnologie in breve tempo. In aggiunta al background accademico, tutto ciò ha arricchito molto il bagaglio di competenze informatiche.\\
\item \textit{Realizzata un'infrastruttura fedele ai requisiti iniziali.}\\
Terminato il progetto, è stata realizzata un'infrastruttura che rispetta i requisiti e i vincoli imposti nel corso del tirocinio, seppur con piccole modifiche rispetto a quanto fatto in sede di progettazione.\\
Durante la fase di implementazione è stato reso necessario il non utilizzo di Nexus per il repository Docker privato a causa di ostacoli tecnici deviando quindi su un normale Docker Hub privato per non sforare con i tempi.
\end{itemize}
\section{miglioramenti}
Per quanto riguarda eventuali miglioramenti futuri, ciò che si potrebbe aggiungere è un sistema di monitoraggio dell'intero sistema. Allo stato attuale il controllo e la gestione delle risorse viene eseguito manualmente da shell, ma si potrebbe invece implementare un sistema più sofisticato utilizzando qualche tool esterno come ad esempio Grafana.
%
%			BIBLIOGRAFIA
%
\begin{thebibliography}{00}
%
\bibitem{iacdef}
Wikipedia, Infrastructure As Code. \url{https://it.wikipedia.org/wiki/Infrastructure_as_Code}

\bibitem{devopsloopimg}
Shalb, What is DevOps and where is it applied? 2019.\url{https://shalb.com/blog/what-is-devops-and-where-is-it-applied/}

\bibitem{devopsloop}
TechTarget, Demystify the DevOps process, step by step, 2023. \url{https://www.techtarget.com/searchitoperations/tip/Demystify-the-DevOps-process-step-by-step}

\bibitem{docker}
Wikipedia, Docker. \url{https://it.wikipedia.org/wiki/Docker#Orchestrazione}

\bibitem{dockerimg}
Mindmajix, Docker Container Software And Architecture, 2023. \url{https://mindmajix.com/docker-architecture}

\bibitem{kubernetes}
Wikipedia, Kubernetes. \url{https://it.wikipedia.org/wiki/Kubernetes}

\bibitem{k8simg}
Datafusionspecialists, Containerization and Cloud Mobility, 2019. \url{https://datafusionspecialists.com/solutions/containerization-and-cloud-mobility/}

\bibitem{cloud}
Ionos.it, I vantaggi del cloud computing. 2023 \url{https://www.ionos.it/digitalguide/server/know-how/i-vantaggi-del-cloud-computing/}

\bibitem{terraformimg}
Auth0, Community Developer Brings HashiCorp Terraform to Auth0, 2020. \url{https://auth0.com/blog/community-developer-brings-hashicorp-terraform-to-auth0/}

\bibitem{jenkins}
Wikipedia, Jenkins. \url{https://it.wikipedia.org/wiki/Jenkins_(software)}

\bibitem{jenkinsimg}
Slideshare, Jenkins Pipeline, 2019. \url{https://www.slideshare.net/pavan5780/jenkins-pipeline-164020728}

%
%
\end{thebibliography}
% 
\end{document}


 
